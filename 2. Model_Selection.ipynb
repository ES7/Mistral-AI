{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f501ffce-f4f6-4701-8dd3-3ed32a5134ba",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "Mistral AI provides 5 API endpoints featuring 5 leading language models.<br>\n",
    "<img src=\"models.png\" width=\"250\" height=\"150\">\n",
    "<img src=\"graph.png\" width=\"400\" height=\"150\"><br>\n",
    "Looking at the model performance such as the Multitask Language Understanding (MMLU) task. Mistral-large outperforms the rest of the models in every benchmark including reasoning, multilingual tasks, mathematics and coding. However performance might not be the only consideration here.\n",
    "For our applications, we might also want to consider pricing. Mistral offers competitive pricing on their models. And itâ€™s worth considering the performance pricing trade-offs.<br>\n",
    "![](comp.png)\n",
    "**1. Mistral-small â†’** simple tasks that one can do in bulk (classification, customer support text generation).<br>\n",
    "**2. Mistral-medium â†’** intermediate tasks that require moderate reasoning (data extraction, summarizing a document, writing emails, writing a job description, writing product descriptions).<br>\n",
    "**3. Mistral-large â†’** complex tasks that require large reasoning capabilities or are highly specialized (synthetic text generation, code generation, RAG, Agents).<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4896b6d5-9e73-4fd1-9fc0-8a7cb93bb750",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from helper import load_mistral_api_key\n",
    "api_key, dlai_endpoint = load_mistral_api_key(ret_key=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51403fae-91e9-4e24-9353-02495cb2babc",
   "metadata": {
    "height": 302
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "def mistral(user_message, model=\"mistral-small-latest\", is_json=False):\n",
    "    client = MistralClient(api_key=api_key, endpoint=dlai_endpoint)\n",
    "    messages = [ChatMessage(role=\"user\", content=user_message)]\n",
    "\n",
    "    if is_json:\n",
    "        chat_response = client.chat(\n",
    "            model=model, messages=messages, response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "    else:\n",
    "        chat_response = client.chat(model=model, messages=messages)\n",
    "\n",
    "    return chat_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03db3133-63d2-4cc7-b562-efce0991a143",
   "metadata": {},
   "source": [
    "## Mistral Small\n",
    "First we will use Mistral-small for simpler tasks like classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18eaa6a5-6653-4587-8077-e409191c790b",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Classify the following email to determine if it is spam or not.\n",
    "Only respond with the exact text \"Spam\" or \"Not Spam\". \n",
    "\n",
    "# Email:\n",
    "ðŸŽ‰ Urgent! You've Won a $1,000,000 Cash Prize! \n",
    "ðŸ’° To claim your prize, please click on the link below: \n",
    "https://bit.ly/claim-your-prize\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663d8e4e-9ca9-4446-837b-f34c301f77b6",
   "metadata": {},
   "source": [
    "Let's try to classify an email as spam or not spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11cef6cd-bb24-46c5-9e83-2d81168057eb",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spam'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral(prompt, model=\"mistral-small-latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac31f9e-8446-417c-aec8-598e141686bc",
   "metadata": {},
   "source": [
    "All the models are good at such tasks but using mistral-small for such tasks is more effective and fast.\n",
    "\n",
    "## Mistral Medium\n",
    "Now we will use Mistral-medium to perform some intermediate tasks like language transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87ce9677-a0a2-40ef-903d-571561c0fc65",
   "metadata": {
    "height": 268
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Compose a welcome email for new customers who have just made \n",
    "their first purchase with your product. \n",
    "Start by expressing your gratitude for their business, \n",
    "and then convey your excitement for having them as a customer. \n",
    "Include relevant details about their recent order. \n",
    "Sign the email with \"The Fun Shop Team\".\n",
    "\n",
    "Order details:\n",
    "- Customer name: Anna\n",
    "- Product: hat \n",
    "- Estimate date of delivery: Feb. 25, 2024\n",
    "- Return policy: 30 days\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a9b5f5-59e4-42eb-85ea-5ad4e62397c1",
   "metadata": {},
   "source": [
    "Here we asking the model to compose emails for new customers who have just made their first purchase with our product. Make sure we have mentioned the order details in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e0bb8a6-5be9-4a83-9413-14e154c845de",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "response_medium = mistral(prompt, model=\"mistral-medium-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6de3dada-f0e1-4dee-9a41-31cac83256b0",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Welcome to The Fun Shop, Anna! Thank you for your first purchase.\n",
      "\n",
      "Dear Anna,\n",
      "\n",
      "We are thrilled to have you as a new customer at The Fun Shop! We want to express our sincere gratitude for your recent purchase of our stylish hat. Your support means the world to us.\n",
      "\n",
      "We are excited for you to enjoy your new hat, and we hope it brings a touch of fun and joy to your wardrobe. Your order is currently being processed, and we anticipate that it will be delivered to you by February 25, 2024. Please keep an eye out for the tracking information, which will be sent to you via email once your order has been shipped.\n",
      "\n",
      "If for any reason you are not completely satisfied with your purchase, please know that we offer a 30-day return policy. We want to make sure that you are completely happy with your new hat, and if it doesn't meet your expectations, we are here to help.\n",
      "\n",
      "Thank you once again for choosing The Fun Shop. If you have any questions or concerns, please don't hesitate to reach out to our customer support team. We are always here to help.\n",
      "\n",
      "Wishing you a fun and fabulous day!\n",
      "\n",
      "Best regards,\n",
      "The Fun Shop Team\n"
     ]
    }
   ],
   "source": [
    "print(response_medium)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3b2c99-c01a-4beb-8685-355f6c21ce55",
   "metadata": {},
   "source": [
    "## Mistral Large\n",
    "Mistral-large is great for complex tasks that require advanced reasoning capabilities or that are highly specialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc4c9957-48dc-46b8-bb6f-f506af1f768f",
   "metadata": {
    "height": 268
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Calculate the difference in payment dates between the two \\\n",
    "customers whose payment amounts are closest to each other \\\n",
    "in the following dataset. Do not write code.\n",
    "\n",
    "# dataset: \n",
    "'{\n",
    "  \"transaction_id\":{\"0\":\"T1001\",\"1\":\"T1002\",\"2\":\"T1003\",\"3\":\"T1004\",\"4\":\"T1005\"},\n",
    "    \"customer_id\":{\"0\":\"C001\",\"1\":\"C002\",\"2\":\"C003\",\"3\":\"C002\",\"4\":\"C001\"},\n",
    "    \"payment_amount\":{\"0\":125.5,\"1\":89.99,\"2\":120.0,\"3\":54.3,\"4\":210.2},\n",
    "\"payment_date\":{\"0\":\"2021-10-05\",\"1\":\"2021-10-06\",\"2\":\"2021-10-07\",\"3\":\"2021-10-05\",\"4\":\"2021-10-08\"},\n",
    "    \"payment_status\":{\"0\":\"Paid\",\"1\":\"Unpaid\",\"2\":\"Paid\",\"3\":\"Paid\",\"4\":\"Pending\"}\n",
    "}'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e8e443-cc5d-448f-8b93-03f415a555f1",
   "metadata": {},
   "source": [
    "In this example let's ask the model to calculate the difference in payment dates between the two customers whose payment amount are close to each other in a given dataset. First let's try using mistral-small on this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba02ea8b-8872-4a7d-8195-6285e4b422a3",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "response_small = mistral(prompt, model=\"mistral-small-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74554e58-25a0-402d-95ad-8ada5c0cc743",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve this problem, first, we need to find the two customers whose payment amounts are closest to each other. From the given dataset, we can see that the payment amounts are: 125.5, 89.99, 120.0, 54.3, and 210.2.\n",
      "\n",
      "The two closest amounts are 120.0 and 125.5. Now, we need to find the customers and their corresponding payment dates.\n",
      "\n",
      "Customer C001 made a payment of 125.5 on 2021-10-05.\n",
      "Customer C003 made a payment of 120.0 on 2021-10-07.\n",
      "\n",
      "So, the difference in payment dates between these two customers is 2 days (2021-10-07 minus 2021-10-05).\n"
     ]
    }
   ],
   "source": [
    "print(response_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5a6f1d-2764-4878-ad47-88531ce6bee8",
   "metadata": {},
   "source": [
    "Here we can see that the mistral-small gives incorrect answer. But since the model results are probabilistic if we actually run it multiple times it might sometimes give the correct result.\n",
    "Now let's try to perform the same task on mistral-large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "987a0aef-67dc-4ada-82ac-4b0dc1b6b5ae",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "response_large = mistral(prompt, model=\"mistral-large-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f21a55c1-c700-4bf3-be22-5ad432dc3f10",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve this problem without writing code, we first need to identify the two customers whose payment amounts are closest to each other.\n",
      "\n",
      "The payment amounts are as follows:\n",
      "1. C001: 125.5, 210.2\n",
      "2. C002: 89.99, 54.3\n",
      "3. C003: 120.0\n",
      "\n",
      "The closest payments are 125.5 (C001) and 120.0 (C003), with a difference of 5.5.\n",
      "\n",
      "Next, we need to calculate the difference in payment dates between these two customers.\n",
      "\n",
      "The payment dates are as follows:\n",
      "1. C001: 2021-10-05, 2021-10-08\n",
      "2. C002: 2021-10-06, 2021-10-05\n",
      "3. C003: 2021-10-07\n",
      "\n",
      "The relevant payment dates are 2021-10-05 (C001) and 2021-10-07 (C003). The difference in payment dates is 2 days.\n"
     ]
    }
   ],
   "source": [
    "print(response_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15be44d-ecb4-47f6-bed5-5b08c6bc391a",
   "metadata": {},
   "source": [
    "As we can see mistral-large splits the question into multiple steps and is able to give us the right answer.\n",
    "\n",
    "## Numerical\n",
    "Let's try another example in which we will ask the models to calculate expenses on each categories like resturants, groceries, stuffed animals and props."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7c1deb9-37f4-4182-b43c-3bad2637598c",
   "metadata": {
    "height": 353
   },
   "outputs": [],
   "source": [
    "transactions = \"\"\"\n",
    "McDonald's: 8.40\n",
    "Safeway: 10.30\n",
    "Carrefour: 15.00\n",
    "Toys R Us: 20.50\n",
    "Panda Express: 10.20\n",
    "Beanie Baby Outlet: 25.60\n",
    "World Food Wraps: 22.70\n",
    "Stuffed Animals Shop: 45.10\n",
    "Sanrio Store: 85.70\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Given the purchase details, how much did I spend on each category:\n",
    "1) restaurants\n",
    "2) groceries\n",
    "3) stuffed animals and props\n",
    "{transactions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c534c567-cd20-4abb-adbc-cc9fe919c2f8",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To categorize your purchases, we can make the following assumptions:\n",
      "\n",
      "1) Restaurants: McDonald's and Panda Express\n",
      "2) Groceries: Safeway and Carrefour\n",
      "3) Stuffed animals and props: Toys R Us, Beanie Baby Outlet, Stuffed Animals Shop, and Sanrio Store\n",
      "\n",
      "Now, let's calculate the total spent in each category:\n",
      "\n",
      "1) Restaurants:\n",
      "   McDonald's: $8.40\n",
      "   Panda Express: $10.20\n",
      "   Total: $18.60\n",
      "\n",
      "2) Groceries:\n",
      "   Safeway: $10.30\n",
      "   Carrefour: $15.00\n",
      "   Total: $25.30\n",
      "\n",
      "3) Stuffed animals and props:\n",
      "   Toys R Us: $20.50\n",
      "   Beanie Baby Outlet: $25.60\n",
      "   Stuffed Animals Shop: $45.10\n",
      "   Sanrio Store: $85.70\n",
      "   Total: $176.90\n",
      "\n",
      "So, you spent $18.60 on restaurants, $25.30 on groceries, and $176.90 on stuffed animals and props.\n"
     ]
    }
   ],
   "source": [
    "response_small = mistral(prompt, model=\"mistral-small-latest\")\n",
    "print(response_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e517bb-9098-4d77-9652-3179996acb38",
   "metadata": {},
   "source": [
    "Running mistral-small on this we can observe some mistakes in the output. Let's try running mistral-large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47960a78-7689-47ee-adee-6c8412d5477b",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the purchase details you provided, here's the breakdown of your spending in each category:\n",
      "\n",
      "1) Restaurants:\n",
      "   - McDonald's: $8.40\n",
      "   - Panda Express: $10.20\n",
      "   - World Food Wraps: $22.70\n",
      "   Total spending on restaurants: $41.30\n",
      "\n",
      "2) Groceries:\n",
      "   - Safeway: $10.30\n",
      "   - Carrefour: $15.00\n",
      "   Total spending on groceries: $25.30\n",
      "\n",
      "3) Stuffed animals and props:\n",
      "   - Toys R Us: $20.50\n",
      "   - Beanie Baby Outlet: $25.60\n",
      "   - Stuffed Animals Shop: $45.10\n",
      "   - Sanrio Store: $85.70\n",
      "   Total spending on stuffed animals and props: $176.90\n"
     ]
    }
   ],
   "source": [
    "response_large = mistral(prompt, model=\"mistral-large-latest\")\n",
    "print(response_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90d6068-61b3-4490-aeb4-0be67ba9fd1b",
   "metadata": {},
   "source": [
    "Mistral-large gives correct answers for each categories.\n",
    "\n",
    "## Writing and checking code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27945975-d2bc-40b9-9a59-48b10fe4da4b",
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "user_message = \"\"\"\n",
    "Given an array of integers nums and an integer target, return indices of the two numbers such that they add up to target.\n",
    "\n",
    "You may assume that each input would have exactly one solution, and you may not use the same element twice.\n",
    "\n",
    "You can return the answer in any order.\n",
    "\n",
    "Your code should pass these tests:\n",
    "\n",
    "assert twoSum([2,7,11,15], 9) == [0,1]\n",
    "assert twoSum([3,2,4], 6) == [1,2]\n",
    "assert twoSum([3,3], 6) == [0,1]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e00a7bc-069a-43f9-bb02-e33a5d3dcc2f",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I can help you with that. Here's a Python function that should do the trick:\n",
      "\n",
      "```python\n",
      "def twoSum(nums, target):\n",
      "    if len(nums) < 2:\n",
      "        return \"Not enough numbers in the array\"\n",
      "\n",
      "    num_dict = {}\n",
      "    for i, num in enumerate(nums):\n",
      "        if target - num in num_dict:\n",
      "            return [num_dict[target - num], i]\n",
      "        else:\n",
      "            num_dict[num] = i\n",
      "\n",
      "    return \"No two numbers in the array add up to the target\"\n",
      "```\n",
      "\n",
      "This function works by iterating through the array and keeping track of the numbers and their indices in a dictionary. For each number, it checks if the difference between the target and the current number is in the dictionary. If it is, it means that we have found two numbers that add up to the target, and we return their indices. If we go through the entire array and don't find any such pair, we return a message indicating that no such pair exists.\n",
      "\n",
      "Please note that the function will return a list of indices that add up to the target. The order of the indices in the returned list may not be the same as their order in the input list. If you need the indices to be in the same order as they appear in the input list, you can modify the return statement to `return [i, num_dict[target - num]]]`.\n",
      "\n",
      "You can test the function with the test cases you provided like this:\n",
      "\n",
      "```python\n",
      "assert twoSum([2,7,11,15], 9) == [0,1]\n",
      "assert twoSum([3,2,4], 6) == [1,2]\n",
      "assert twoSum([3,3], 6) == [0,1]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(mistral(user_message, model=\"mistral-large-latest\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db8aa2a-aa1f-45f1-b4a4-d8eedc927677",
   "metadata": {},
   "source": [
    "## Natively Fluent in English, French, Spanish, German, and Italian\n",
    "We can use Mistral models for more than translating from one language to another. If we are a native Spanish speaker, for instance, we can communicate with Mistral models in Spanish for any of our tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cbad716-8da8-4c00-8eb1-889b69567986",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "user_message = \"\"\"\n",
    "Lequel est le plus lourd une livre de fer ou un kilogramme de plume\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72722d49-b12b-4334-bc1c-318874c57959",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Une livre de fer et un kilogramme de plumes ont des poids diffÃ©rents.\n",
      "\n",
      "Une livre est une unitÃ© de mesure utilisÃ©e principalement aux Ã‰tats-Unis et au Royaume-Uni, et elle est Ã©gale Ã  environ 0,453592 kilogrammes. Donc, une livre de fer est plus lÃ©gÃ¨re qu'un kilogramme de plumes.\n",
      "\n",
      "Cependant, il est important de noter que la question peut sembler trompeuse, car on pourrait penser que la rÃ©ponse Ã©vidente est que le fer est plus lourd que les plumes. C'est vrai, mais seulement si l'on compare des quantitÃ©s Ã©gales de chaque matÃ©riau. Dans ce cas, on compare une livre de fer Ã  un kilogramme de plumes, ce qui n'est pas une comparaison juste.\n"
     ]
    }
   ],
   "source": [
    "print(mistral(user_message, model=\"mistral-large-latest\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc301515-157c-450b-828e-554ee6760809",
   "metadata": {},
   "source": [
    "## List of Mistral models that we can call:\n",
    "\n",
    "We can also call the two open source mistral models via API calls.\n",
    "Here is the list of models that you can try:\n",
    "```\n",
    "open-mistral-7b\n",
    "open-mixtral-8x7b\n",
    "open-mixtral-8x22b\n",
    "mistral-small-latest\n",
    "mistral-medium-latest\n",
    "mistral-large-latest\n",
    "```\n",
    "\n",
    "For example:\n",
    "```Python\n",
    "mistral(prompt, model=\"open-mixtral-8x22b\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e316a8f-57fc-4774-980e-118c01239636",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
